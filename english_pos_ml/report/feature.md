# 特徴量エンジニアリング（手法）の解説

このドキュメントでは、本プロジェクトで採用されている「特徴量エンジニアリング」の仕組みと、学習データおよびAIモデルとの関係性について解説します。

---

## 1. 特徴量の構成

本プロジェクトでは、単語を多角的に分析するために、以下の2つのアプローチを組み合わせてAIに渡しています。

### A. 文字レベル TF-IDF (統計的パターン)
*   **内容**: 単語を2〜5文字の断片（n-gram）に分解し、その出現頻度を数値化します。
*   **役割**: 「この綴りのパターンがあるときは、この品詞であることが多い」という統計的な傾向をAIが学ぶためのベースデータです。

### B. 言語的特徴（人間によるヒント）
*   **内容**: `feature_engineering.py` で定義されている、特定の語尾（接尾辞）、語頭（接頭辞）、および単語の構造です。
    *   例: `suffix_ly` (語尾が -ly か？), `suffix_tion` (語尾が -tion か？), `vowel_ratio` (母音の比率)
*   **役割**: 人間（言語学の知識）が「品詞を見極める際に注目すべき重要ポイント」をあらかじめAIに指し示す役割を担います。

---

## 2. 優先順位と決定プロセス

本システムには「ルール」と「AI（学習に基づいた判断）」の優先順位が存在します。

1.  **ルールベース（最優先）**:
    *   助動詞など、リストで100%確定できるものは機械学習を通さず、ルールで即決します。
2.  **AI判断（学習データに基づく重要度調整）**:
    *   AI（SVM、ロジスティック回帰等）は、人間が与えた「ヒント（特徴量）」と「実際の正解（学習データ）」を繰り返し比較します。
    *   例えば、AIは「`suffix_ly` というヒントがある場合、学習データでは9割以上が副詞になっている」という事実を学習し、そのヒントを**重視（重みを高く）**するように自分自身を調整します。
    *   ※特徴量自体が `ly = 副詞` と決めているわけではありません。判定の責任はあくまで学習データの結果に委ねられています。

---

## 3. 深層学習（ディープラーニング）との違い

もし本プロジェクトで、人間による特徴量の指定（ヒント）を一切行わず、生のスペルデータだけをAIに渡す場合、それは**深層学習**的なアプローチに近づきます。

| 比較項目 | 現在の手法（機械学習 + 職人芸） | 深層学習（全自動） |
| :--- | :--- | :--- |
| **特徴量** | 人間が重要なポイントを定義する | AIがデータから独自に発見する（表現学習） |
| **データ量** | 数百〜数千件でも高精度が出せる | 数万件以上の膨大なデータが必要 |
| **計算負荷** | 動作が非常に軽く、CPUで十分実行可能 | 非常に重く、GPUが必要な場合が多い |
| **解釈性** | なぜその品詞と判断したか説明しやすい | 判断の根拠がブラックボックスになりやすい |

### 本プロジェクトの狙い
英単語の品詞分類は、接尾辞などの言語学的な法則が明確であるため、あえて全てをAIの自己学習（深層学習）に任せきるのではなく、**「人間の知識（ヒント）」と「統計的な学習」を組み合わせる**ことで、小規模なデータでも高速かつ正確に動作する実用的なシステムを実現しています。

---

## 4. 例外（イレギュラー）への対応

`suffix_ly=1`（語尾が -ly）であるのに副詞ではない単語（例：`family` = 名詞、`friendly` = 形容詞）などは、以下の仕組みで正しく判定されます。

### A. 特徴量の「多角的判断」
AIは一つのフラグ（ヒント）だけで決めるのではなく、**全ての入力情報を同時に天秤にかけます。**
*   `family` の場合、`suffix_ly=1` というヒントがあっても、同時に抽出されている文字パターン（`fam`, `ami`, `mil` など）が学習データ内の他の名詞と強く一致していれば、AIは「総合的に見て名詞である」と判断します。

### B. 学習データによる「重みの修正」
学習プロセスにおいて、AIは「`-ly` があっても副詞ではない事例」もセットで学習します。
*   これにより、AI内部の数式において `suffix_ly` の重要度が適切に調整され、「特定の文字パターンとセットでない限り、`-ly` だけで副詞と決めつけない」という柔軟な判断基準が構築されます。

### C. 確率的なアプローチ
モデルは「1対0」の固定的な判断ではなく、各品詞の**「正解確率」**を計算します。
*   例外的な単語については、複数の品詞の確率が僅差になることがありますが、最終的に学習データに最も合致する（確率が高い）品詞が選択されます。

---

## 5. 未知の文字列（ヒントにない綴り）への対応

手動で定義したヒント（`-ing`, `-ly` など）に全く該当しない文字列が含まれている場合でも、システムは以下の「セーフティネット」によって判定を継続します。

### A. 文字レベル TF-IDF による「地引網」
手動ヒントが「ピンポイントの狙い撃ち」なら、TF-IDFは**「地引網」**です。単語を2〜5文字のあらゆる断片（n-gram）に分解して数値化するため、人間が定義し忘れた語尾や綴りのパターンであっても、学習データに似た並びがあればAIはそれを見逃さずに手がかりにします。

### B. 単語構造による「消去法的な推測」
具体的な綴りのヒントがゼロであっても、以下の構造的特徴は常に計算されています。
*   単語が極端に短い（前置詞や代名詞の可能性）
*   母音の比率が特異である
*   ハイフンが含まれている
AIはこれらの「綴り以外の情報」を使い、過去の学習データと照らし合わせて「名詞っぽい」などの推測を立てます。

### C. 最終的な確率判断
もし、文字パターンも構造も全く新しい（完全に未知の）単語であった場合、AIはモデル全体で学んだ「品詞の一般的な分布」に基づき、最も可能性の高い品詞（データセット内で頻出する「名詞」など）を最終回答として出します。
