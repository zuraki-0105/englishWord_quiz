# 学習手法の分析結果

## 1. 全体アーキテクチャ
現在のシステムは、**「ルールベース（規則）」と「機械学習（AI）」を組み合わせたハイブリッド構成**をとっています。

### 処理フロー
1.  **ルールベース判定**: `src/rule_based_classifier.py` により、助動詞リスト（`will`, `can` など）に一致する単語を優先的に分類します。
2.  **機械学習判定**: ルールに該当しない単語について、`src/train.py` で構築されたアンサンブルモデルが予測を行います。

---

## 2. 特徴量エンジニアリング（単語の「顔つき」の抽出）
単語のスペルから情報を引き出すために、2つの手法を並列で実行しています（`FeatureUnion`）。

### A. 文字レベル TF-IDF
- **内容**: 2〜5文字の連続する文字パターン（n-gram）を抽出。
- **目的**: 統計的に出現しやすい綴りのパターンを捉えます。

### B. 言語的特徴（Linguistic Features）
- **内容**: `src/feature_engineering.py` で定義。
- **項目**:
  - **接尾辞**: `-ing` (動詞), `-tion` (名詞), `-ful` (形容詞), `-ly` (副詞) など。
  - **接頭辞**: `un-`, `re-`, `dis-` など。
  - **構造**: 単語長、母音比率、ハイフンの有無。
  - **辞書**: WordNet（現在は設定により無効化）。

---

## 3. モデルアルゴリズム（AIの構成）
複数のモデルを組み合わせる「アンサンブル学習（多数決方式）」を採用しています。

- **ベースモデル（計6種類）**:
  - **LinearSVC**: テキスト分類に強い線形SVM（`CalibratedClassifierCV` で確率対応）。
  - **LogisticRegression**: 一般的で汎用性の高い分類。
  - **RandomForestClassifier**: 決定木を多数組み合わせたモデル。
  - **MLPClassifier**: ニューラルネットワーク。複雑な非線形パターンの学習を担当。
  - **SGDClassifier**: 確率的勾配降下法による高速で多様な学習。
  - **KNeighborsClassifier**: スペルの類似性（近傍）に基づく予測。
  
  > 各モデルのより詳細な特徴と役割については、[models.md](models.md) を参照してください。

- **統合手法**:
  - **Voting (Soft)**: 各モデルの予測確率を平均し、最も高いクラスを採用。多様なアルゴリズムの結果を統合することで、個々のモデルのエラーを打ち消し精度を安定させています。

---

## 4. 学習の最適化設定
- **クラス不均衡対応 (`class_weight='balanced'`)**: データ数が少ない品詞（副詞など）を無視せず学習。
- **データフィルタリング**: 学習データが極端に少ない（2件未満）クラスを自動除外し、学習の安定性を確保。
