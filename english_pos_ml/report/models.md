# モデルアルゴリズムの解説

現在のシステムで採用しているアンサンブル学習（VotingClassifier）を構成する6つのモデルについて、それぞれの特徴と役割を解説します。

---

## 1. LinearSVC (線形サポートベクターマシン)
- **特徴**: テキスト分類において非常に強力なモデルです。データを分けるための最適な境界線を学習します。
- **役割**: 文字パターン（TF-IDF）から、品詞を分けるための「決定的な境界」を見つけるのが得意です。
- **補足**: `CalibratedClassifierCV` を使用することで、予測の確信度（確率）を出力できるようにしています。

## 2. LogisticRegression (ロジスティック回帰)
- **特徴**: 統計学に基づいた、非常に安定感のある定番の分類モデルです。
- **役割**: 各特徴量（語尾のパターンや単語長など）がどの程度特定の品詞に寄与しているかをバランスよく学習します。アンサンブルにおける「標準的な判断」を提供します。

## 3. RandomForestClassifier (ランダムフォレスト)
- **特徴**: 多数の決定木を作成し、その合議制で最終決定を下すアンサンブルモデルです。
- **役割**: 「単語が短い、かつ末尾が -y である」といった、複雑な条件分岐の組み合わせ（非線形な関係）を捉えるのが得意です。

## 4. MLPClassifier (ニューラルネットワーク)
- **特徴**: 多層パーセプトロンと呼ばれる、ディープラーニングの基礎となるモデルです。
- **役割**: 他のモデルでは見落とされるような、スペルと品詞の間の「抽象的で複雑な関係性」を多層構造で学習します。

## 5. SGDClassifier (確率的勾配降下法)
- **特徴**: 学習が非常に高速で、大規模データにも対応可能なモデルです。
- **役割**: `log_loss` 設定を使用し、他のモデルとは異なる学習アルゴリズム（逐次的な重み更新）を採用することで、アンサンブル全体に予測の「多様性」をもたらします。

## 6. KNeighborsClassifier (k-近傍法)
- **特徴**: 「綴りが似ている単語は同じ品詞である可能性が高い」という直感に基づき、近接するデータから予測します。
- **役割**: 規則性よりも、既存の単語（学習データ）との「見た目の類似性」を重視した判定を担当します。

---

## アンサンブルの目的
それぞれのモデルには得意・不得意がありますが、これらを `VotingClassifier` (Soft Voting) で統合することで、**個々のモデルの誤判断を他のモデルがカバーする**堅牢な構成になっています。
これにより、特定のアルゴリズムに偏らない、安定した品詞推定を実現しています。
